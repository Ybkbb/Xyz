# Google Gemini-Powered Voice Assistant
# Tested and working on Raspberry Pi Zero W
# By TechMakerAI on YouTube with modifications for optimization

from datetime import date
from io import BytesIO
import threading
import queue
import time
import os
import json  # Added for loading configuration

# turn off the welcome message from pygame package
os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = '1'
os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GLOG_minloglevel"] = "2"

import google.generativeai as genai
from gtts import gTTS
from gpiozero import LED

from pygame import mixer

# Using Raspberry Pi's 3.3v GPIO pins 24 and 25 for LEDs
gled = LED(24)
rled = LED(25)

mixer.pre_init(frequency=24000, buffer=2048)
mixer.init()

# Configuration file path (modify as needed)
config_file = "config.json"

# Load configuration from JSON file
try:
    with open(config_file, "r") as f:
        config = json.load(f)
        my_api_key = config["api_key"]
        model_path = config["model_path"]  # Path to pre-downloaded model
except FileNotFoundError:
    print(f"Error: Configuration file '{config_file}' not found.")
    print("Please create a configuration file with your API key and model path.")
    quit()

# API key validation
if len(my_api_key) < 2:
    print(f"Please add your Google Gemini API key in the configuration file ('{config_file}').")
    quit()

# Set Google Gemini API key (environment variable is not used here)
# genai.configure(api_key=my_api_key)

# Load the pre-downloaded model
model = genai.load_model(model_path)

# Start the chat model
chat = model.start_chat(history=[])

today = str(date.today())

# Initialize the counters
numtext = 0
numtts = 0
numaudio = 0

# Thread 1 for text generation
def chatfun(request, text_queue, llm_done, stop_event):
    global numtext, chat
    response = chat.send_message(request, stream=True)

    shortstring = ''
    ctext = ''

    for chunk in response:
        try:
            if chunk.candidates[0].content.parts:
                ctext = chunk.candidates[0].content.parts[0].text
                ctext = ctext.replace("*", "")

                if len(shortstring) > 10 or len(ctext) > 10:
                    shortstring = "".join([shortstring, ctext])
                    text_queue.put(shortstring)
                    print(shortstring, end='')  # , flush=True)
                    shortstring = ''
                    ctext = ''
                    # time.sleep(0.2)
                else:
                    shortstring = "".join([shortstring, ctext])
                    ctext = ''
        except Exception as e:
            continue

    if len(ctext) > 0:
        shortstring = "".join([shortstring, ctext])

    if len(shortstring) > 0:
        print(shortstring, end='')
        text_queue.put(shortstring)

    numtext += 1

    if numtext > 0:
        append2log(f"AI: {response.candidates[0].content.parts[0].text}\n")
    else:
        llm_done.set()
        stop_event.set()

    llm_done.set()  # Signal completion after the loop

# Convert "text" to audio file and play back
def speak_text(text):
    global slang, rled
    mp3file = BytesIO()
    tts = gTTS(text, lang="en", tld='us')
    tts.write_to_fp(mp3file)

    mp3file.seek(0)
    rled.on()
    print("AI: ", text)

    try:
        mixer.music.load(mp3file, "mp3")
        mixer.music.play()

        while mixer.music.get_busy():
            time.sleep(0.2)

    except KeyboardInterrupt:
        mixer.music.stop()
        mp3file = None
        rled.off()

    mp3file = None

    rled.off()

# Thread 2 for tts
def text2speech(text_queue, tts_done, llm_done, audio_queue, stop_event):

    global numtext, numtts
    time.sleep(1.0)

    while not stop_event.is_set():  # Keep running until stop_event is set

        if not text_queue.empty():

            text = text_queue.get(timeout=1)  # Wait for 1 second for an item

            if len(text) > 0:
                # print(text)
                try:
                    mp3file1 = BytesIO()
                    tts = gTTS(text, lang="en", tld='us')
                    tts.write_to_fp(mp3file1)
                except Exception as e:
                    continue

                audio_queue.put(mp3file1)
                numtts += 1
                text_queue.task_done()

            # print("\n numtts, numtext : ", numtts , numtext)

        if llm_done.is_set() and numtts == numtext:

            time.sleep(0.3)
            tts_done.set()
            mp3file1 = None
            # print("\n break from the text queue" )

            break

# Thread 3 for audio playback
def play_audio(audio_queue, tts_done, stop_event):

    global numtts, numaudio, rled

    # print("start play_audio()")
    while not stop_event.is_set():  # Keep running until stop_event is set

        mp3audio1 = BytesIO()
        mp3audio1 = audio_queue.get()

        mp3audio1.seek(0)

        rled.on()

        mixer.music.load(mp3audio1, "mp3")
        mixer.music.play()

        # print("Numaudio: ", numaudio )

        while mixer.music.get_busy():
            time.sleep(0.2)

        numaudio += 1
        audio_queue.task_done()

        # print("\n numtts, numaudio : ", numtts , numaudio)

        rled.off()

        if tts_done.is_set() and numtts == numaudio:
            mp3audio1 = None
            # print("\n no more audio/text data, breaking from audio thread")
            break  # Exit loop

# Save conversation to a log file
def append2log(text):
    global today
    fname = 'chatlog-' + today + '.txt'
    with open(fname, "a", encoding='utf-8') as f:
        f.write(text + "\n")
        f.close

# Define default language to work with the AI model
slang = "en-EN"

# Main function
def main():
    global today, slang, numtext, numtts, numaudio, messages, rled, gled

    rec = sr.Recognizer()
    mic = sr.Microphone()

    rec.energy_threshold = 4000

    sleeping = True
    # while loop for conversation
    while True:

        with mic as source:

            rec.adjust_for_ambient_noise(source, duration=1)
            rec.dynamic_energy_threshold = True

            try:
                gled.on()
                print("Listening ...")

                audio = rec.listen(source, timeout=10)  # , phrase_time_limit = 30)
                text = rec.recognize_google(audio, language=slang)  # rec.recognize_wit(audio, key=wit_api_key ) #
                # print(text)

                if len(text) > 0:
                    print(f"You: {text}\n ")
                else:
                    print(f"Unable to recognize your speech. Program will exit. \n ")
                    break

                gled.off()

                # AI is in sleeping mode
                if sleeping == True:
                    # User can start the conversation with the wake word "Jack"
                    # This word can be chagned below.
